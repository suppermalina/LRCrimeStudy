pfm.dal80.jasparCORE <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPARCORE")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-ScerTF")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.jaspar2014,pfm.dal80.jasparCORE, pfm.dal80.scertf)))
pfm.dal80.jaspar2014 <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPAR2014")
pfm.dal80.jasparCORE <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPARCORE")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-ScerTF")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-ScerTF")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "dal80")[[5]],
name="DAL80-ScerTF")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.jaspar2014,pfm.dal80.jasparCORE, pfm.dal80.scertf)))
pfm.dal80.JASPARCORE <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPARCORE")
pfm.dal80.JASPAR2014 <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPAR2014")
pfm.dal80.JASPAR2016 <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-JASPAR2016")
pfm.dal80.JASPAR2018 <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-JASPAR2018")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "harbison")[[5]],
name="DAL80-ScerTF")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.JASPARCORE,pfm.dal80.JASPAR2014, pfm.dal80.JASPAR2016, pfm.dal80.JASPAR2018, pfm.dal80.scertf)))
pfm.dal80.JASPARCORE <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPARCORE")
pfm.dal80.JASPAR2014 <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPAR2014")
pfm.dal80.JASPAR2016 <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-JASPAR2016")
pfm.dal80.JASPAR2018 <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-JASPAR2018")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "harbison")[[1]],
name="DAL80-ScerTF")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.JASPARCORE,pfm.dal80.JASPAR2014, pfm.dal80.JASPAR2016, pfm.dal80.JASPAR2018, pfm.dal80.scertf)))
pfm.dal80.JASPAR2014 <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPARCORE")
pfm.dal80.JASPARCORE <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPAR2014")
pfm.dal80.JASPAR2016 <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-JASPAR2016")
pfm.dal80.JASPAR2018 <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-JASPAR2018")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "dal80")[[5]],
name="DAL80-ScerTF")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.JASPAR2014,pfm.dal80.JASPARCORE, pfm.dal80.JASPAR2016, pfm.dal80.JASPAR2018, pfm.dal80.scertf)))
pfm.dal80.JASPAR2014 <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPARCORE")
pfm.dal80.JASPARCORE <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPAR2014")
pfm.dal80.JASPAR2016 <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-JASPAR2016")
pfm.dal80.JASPAR2018 <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-JASPAR2018")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "harbison")[[5]],
name="DAL80-ScerTF")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.JASPAR2014,pfm.dal80.JASPARCORE, pfm.dal80.JASPAR2016, pfm.dal80.JASPAR2018, pfm.dal80.scertf)))
query(MotifDb, "harbison")
query(MotifDb, "harbison")[[5]]
query(MotifDb, "harbison")[[1]]
pfm.dal80.JASPAR2014 <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPARCORE")
pfm.dal80.JASPARCORE <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPAR2014")
pfm.dal80.JASPAR2016 <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-JASPAR2016")
pfm.dal80.JASPAR2018 <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-JASPAR2018")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "harbison")[[1]],
name="DAL80-ScerTF")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.JASPAR2014,pfm.dal80.JASPARCORE, pfm.dal80.JASPAR2016, pfm.dal80.JASPAR2018, pfm.dal80.scertf)))
pfm.dal80.scertf <- query(MotifDb,"DAL80")[[1]]
pfm.dal80.scertf
seqLogo(pfm.dal80.scertf)
seqLogo(pfm.dal80.jaspar)
pfm.dal80.jaspar
pfm.dal80.scertf <- query(MotifDb,"DAL80")[[3]]
pfm.dal80.scertf
seqLogo(pfm.dal80.scertf)
pfm.dal80.JASPARCORE <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPARCORE")
pfm.dal80.JASPAR2014 <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPAR2014")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-ScerTF")
pfm.dal80.JASPAR2016 <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-JASPAR2016")
pfm.dal80.JASPAR2018 <- new("pfm", mat=query(MotifDb, "harbison")[[1]],
name="DAL80-JASPAR2018")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.JASPAR2014,pfm.dal80.JASPARCORE, pfm.dal80.JASPAR2016, pfm.dal80.JASPAR2018, pfm.dal80.scertf)))
pfm.dal80.JASPARCORE <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPARCORE")
pfm.dal80.JASPAR2014 <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPAR2014")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-ScerTF")
pfm.dal80.JASPAR2016 <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-JASPAR2016")
pfm.dal80.JASPAR2018 <- new("pfm", mat=query(MotifDb, "harbison")[[5]],
name="DAL80-JASPAR2018")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.JASPAR2014,pfm.dal80.JASPARCORE, pfm.dal80.JASPAR2016, pfm.dal80.JASPAR2018, pfm.dal80.scertf)))
query(MotifDb, "harbison")[[5]]
pfm.dal80.JASPARCORE <- new("pfm", mat=query(MotifDb, "dal80")[[1]],
name="DAL80-JASPARCORE")
pfm.dal80.JASPAR2014 <- new("pfm", mat=query(MotifDb, "dal80")[[2]],
name="DAL80-JASPAR2014")
pfm.dal80.scertf <- new("pfm", mat=query(MotifDb, "dal80")[[3]],
name="DAL80-ScerTF")
pfm.dal80.JASPAR2016 <- new("pfm", mat=query(MotifDb, "dal80")[[4]],
name="DAL80-JASPAR2016")
pfm.dal80.JASPAR2018 <- new("pfm", mat=query(MotifDb, "dal80")[[5]],
name="DAL80-JASPAR2018")
plotMotifLogoStack(DNAmotifAlignment(c(pfm.dal80.JASPAR2014,pfm.dal80.JASPARCORE, pfm.dal80.JASPAR2016, pfm.dal80.JASPAR2018, pfm.dal80.scertf)))
library(corrplot)
install.packages("corrplot")
library(corrplot)
corr_iris <- cor(iris)
iris
corr_iris <- cor(iris[, -5])
corr_iris
corr_iris <- round(corr_iris, 2)
corr_iris
corrplot(corr_iris, method = "shade", type = "upper")
corr_iris
fake_iris <- iris[, -5]
iris[1, ]
temp <- iris[1, ]
iris[1, ] <- iris[2, ]
iris[2, ] <- temp
iris
fake_iris <- iris[, -5]
temp <- fake_iris[1, ]
fake_iris[1, ] <- fake_iris[2, ]
fake_iris[2, ] <- temp
fake_iris
corr_iris <- cor(fake_irisÃŸ)
corr_iris <- round(corr_iris, 2)
corrplot(corr_iris, method = "shade", type = "upper")
corr_iris <- cor(fake_iris)
corr_iris <- round(corr_iris, 2)
corrplot(corr_iris, method = "shade", type = "upper")
colnames(fake_iris)
fake_iris <- names(c("Sepal.Length", "Sepal.Width",  "Petal.Length", "Petal.Width"))
fake_iris
fake_iris <- iris[, -5]
temp <- fake_iris[1, ]
fake_iris[1, ] <- fake_iris[2, ]
fake_iris[2, ] <- temp
fake_iris
corr_iris <- cor(fake_iris)
corr_iris <- round(corr_iris, 2)
class(fake_iris)
fake_iris <- colnames(c("Sepal.Length", "Sepal.Width",  "Petal.Length", "Petal.Width"))
fake_iris
fake_iris <- iris[, -5]
temp <- fake_iris[1, ]
fake_iris[1, ] <- fake_iris[2, ]
fake_iris[2, ] <- temp
fake_iris
fake_iris <- iris[, -5]
temp <- fake_iris[1, ]
fake_iris[1, ] <- fake_iris[2, ]
fake_iris[2, ] <- temp
fake_iris <- colnames(c("Sepal.Length", "Sepal.Width",  "Petal.Length", "Petal.Width"))
fake_iris
corr_iris <- cor(fake_iris)
corrplot(corr_iris, method = "shade", tl.col = "blue", tl.srt = 45, type = "upper",
addCoef.col = "black", order = "hclust")
corrplot(corr_iris, method = "shade", tl.col = "blue", tl.srt = 45, type = "up",
addCoef.col = "black", order = "hclust")
corrplot(corr_iris, method = "shade", shade.col = NA, tl.col = "blue", tl.srt = 45, type = "up",
addCoef.col = "black", order = "hclust")
mtcars
cluster_data <- data.frame(mpg = mtcars$mpg, dis = mtcars$disp, hp = mtcars$hp, drat = mtcars$drat,
wt = mtcars$wt)
cluster_data
rownames(mtcars)
rownames(cluster_data) <- rownames(mtcars)
cluster_data
cars_cluster <- hclust(dist(cluster_data))
plot(cars_cluster, hang = -1)
install.packages("RgoogleMaps")
p <- ggmap::ggmap(get_map(center = c(lon = -92.331111, lat = 34.736111),
zoom = 11, scale = 2,
maptype ='terrain',
color = 'color'))
p + geom_point(aes(x = LONGITUDE, y = LATITUDE,  colour = OFFENSE_DESCRIPTION), data = incidents, size = 0.5) +
theme(legend.position="bottom")
p
map <- get_map(location = c(lon = -92.331111,
lat = 34.736111),
api_key="AIzaSyCZfi5P3x1fkY7hdYonyyduIXWDzMnfW54",
zoom = 6,
maptype = "terrain",
source = "google",
messaging = TRUE
)
options("googleAuthR.client_secret" = "AIzaSyCZfi5P3x1fkY7hdYonyyduIXWDzMnfW54")
options("googleAuthR.scopes.selected" =
c("https://maps.googleapis.com/maps/api/geocode/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA&key=AIzaSyCZfi5P3x1fkY7hdYonyyduIXWDzMnfW54"))
install.packages("RgoogleMaps")
install.packages("RgoogleMaps")
map <- get_map(location = c(lon = -92.331111,
lat = 34.736111),
api_key="AIzaSyCZfi5P3x1fkY7hdYonyyduIXWDzMnfW54",
zoom = 6,
maptype = "terrain",
source = "google",
messaging = TRUE
)
p <- ggmap::ggmap(get_map(center = c(lon = -92.331111, lat = 34.736111),
zoom = 11, scale = 2,
maptype ='terrain',
color = 'color'))
if(!requireNamespace("devtools")) install.packages("devtools")
devtools::install_github("dkahle/ggmap", ref = "tidyup")
if(!requireNamespace("devtools")) install.packages("devtools")
devtools::install_github("dkahle/ggmap", ref = "tidyup", force = TRUE)
library("ggmap")
citation("ggmap")
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
install.packages("plyr")
install.packages("plyr")
install.packages("plyr")
install.packages("plyr")
# create a list of all installed packages
ip <- as.data.frame(installed.packages())
head(ip)
# if you use MRO, make sure that no packages in this library will be removed
ip <- subset(ip, !grepl("MRO", ip$LibPath))
# we don't want to remove base or recommended packages either\
ip <- ip[!(ip[,"Priority"] %in% c("base", "recommended")),]
# determine the library where the packages are installed
path.lib <- unique(ip$LibPath)
# create a vector with all the names of the packages you want to remove
pkgs.to.remove <- ip[,1]
head(pkgs.to.remove)
# remove the packages
sapply(pkgs.to.remove, remove.packages, lib = path.lib)
if(!requireNamespace("devtools")) install.packages("devtools")
devtools::install_github("dkahle/ggmap", ref = "tidyup", force = TRUE)
library("ggmap")
citation("ggmap")
#The following three lines used to test if the ggmap has been installed properly
us <- c(left = -125, bottom = 25.75, right = -67, top = 49)
map <- get_stamenmap(us, zoom = 5, maptype = "toner-lite")
ggmap(map)
#Functions to work with date-times and time-spans: fast and user friendly parsing of date-time data,
#extraction and updating of components of a date-time (years, months, days, hours, minutes, and seconds),
#algebraic manipulation on date-time and time-span objects.
#The 'lubridate' package has a consistent and memorable syntax that makes working with dates easy and fun.
#Parts of the 'CCTZ' source code, released under the Apache 2.0 License,
#are included in this package. See <https://github.com/google/cctz> for more details.
install.packages("lubridate")
install.packages("Hmisc")
install.packages("reshape")
install.packages("psych")
#A set of tools that solves a common set of problems: you
#need to break a big problem down into manageable pieces,
#operate on each piece and then put all the pieces back together.
#For example, you might want to fit a model to each spatial location or time point in your study,
#summarise data by panels or collapse high-dimensional arrays to simpler summary statistics.
#The development of 'plyr' has been generously supported by 'Becton Dickinson'.
update.packages("plyr")
#A fast, consistent tool for working with data frame like objects, both in memory and out of memory.
update.packages("dplyr")
update.packages("ggplot2")
update.packages("forcats")
update.packages("stringr")
setwd("/Users/mali/Documents/myGit/LRCrimeStudy/code")
#Loading the packages
library(plyr)
library(lubridate)
library(dplyr)
library(ggplot2)
library (psych)
#Loading data
# This script aims to study the crimes happened in LR.
# Data are downloaded from the police department of LR.
# The data set has following records:
# INCIDENT_DATA, data form: month/day/year hour_miutes_second AM/PM
# INCIDENT_NUMBER, data form: year-xxxxxx(six digits)
# LOCATION_DISTRICT, data form: two digits number
# OFFENS_CODE, data form: two digits with a uppercase letter
# OFFENS_DESCRIPTION: a string
# LOCATION_ADDRESS,CITY,STATE,ZIP
# LATITUDE,LONGITUDE
# Location: street name only
#Data set can be found on this webpage:
#https://data.littlerock.gov/Safe-City/Little-Rock-Police-Department-Statistics-2017-to-Y/bz82-34ep
#Peeking at the data set
#Here, the data.frame incidents contains data for 2017, 2018.
#We need this dataframe for analysising the distribution of crimes per hour in each week
incidents <- read.table("/Users/mali/Documents/myGit/LRCrimeStudy/data/Little_Rock_Police_Department_Statistics_2017_to_Year_to_Date_2018.csv",
head=TRUE, sep=",", fill=TRUE, stringsAsFactors=F)
head(incidents)
attach(incidents)
str(incidents)
incidents$INCIDENT_DATE <- gsub("\\/", "\\-", incidents$INCIDENT_DATE)
incidents$ymd <- mdy_hms(incidents$INCIDENT_DATE)
incidents$month <- month(incidents$ymd, label = TRUE)
incidents$year <- year(incidents$ymd)
incidents$wday <- wday(incidents$ymd, label = TRUE)
incidents$hour <- hour(incidents$ymd)
#This dataframe contains all crime records from 2015-2018
total_incidents <- read.table("/Users/mali/Documents/myGit/LRCrimeStudy/data/Crime_records_Of_LR_2015-2018.csv", head=TRUE, sep=",", fill=TRUE, stringsAsFactors=F)
#First, we hope to have a big picture of the crimes happened in the time range, more accurate,
#we want to see which types of crimes commited the most
#Thus, we will show the total count of each typ of crime with a barplot
incidentsSummary <- as.data.frame(total_incidents %>%
group_by(incidents_Description) %>%
summarise(offense_amount = n()) %>%
distinct())
attach(incidentsSummary)
colnames(incidentsSummary) <- c("offense_description", "offense_amount")
#The following codes are for the bar chart
p <- ggplot(incidentsSummary, aes(x = reorder(incidentsSummary$offense_description, desc(incidentsSummary$offense_amount)),
y = incidentsSummary$offense_amount))
p + geom_bar(stat = "identity", width = 0.8, fill = "red") +
coord_flip() +
labs(title = "CATAGORIED CRIME COUNT", x = "OFFENSE_DESCRIPTION", y = "OFFENSE_AMOUNT")
#The following codes aim to plot out the pie chart
pie <- ggplot(incidentsSummary, aes(x = "", y = incidentsSummary$offense_amount, fill = factor(incidentsSummary$offense_description)))
pie + geom_bar(width = 1, stat = "identity") +
theme(axis.line = element_blank(), plot.title = element_text(hjust = 0.5)) +
labs(fill = "OFFENSE_DESCRIPTION", x = NULL, y = NULL, title = "PIE OF TOP20",
caption = "Source:OFFENSE_DESCRIPTION") +
coord_polar(theta = "y", start = 0)
#Second, we hope to figuer out how the crimes distribute in each weekday, from 0:00 to 23:59
#For, this part, we will use a heatmap to show the relation. And, we will use all crime records
#setting colors
col1 = "#FEFEFE"
col2 = "#540404"
weekdayHour <- ddply(incidents, c("hour", "wday"), summarise, N = length(ymd))
weekdayHour$wday <- factor(weekdayHour$wday, levels=rev(levels(weekdayHour$wday)))
#creating the heatmap
ggplot(weekdayHour, aes(hour, wday)) + geom_tile(aes(fill = N),colour = "white", na.rm = TRUE) +
scale_fill_gradient(low = col1, high = col2) +
guides(fill=guide_legend(title="Total Incidents")) +
theme_bw() + theme_minimal() +
labs(title = "Heatmap of LR crimes by Hour of a day",
x = "Hour", y = "Day of Week") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
#Third, science the coordinations of all locations where incidents commited, we want to see
#them being marked on the map
library("dplyr")
library("forcats")
register_google(key = "AIzaSyAj3UsfYVSZOvDk8wD2Xo8pIqtiTq_bRhI", account_type = "premium", day_limit = 100000)
#Overall heatmap
geo_incidents <- ddply(total_incidents, c("OFFENSE_DESCRIPTION",
"LATITUDE", "LONGITUDE"), summarise, N = length(OFFENSE_DESCRIPTION))
geo_incidents$OFFENSE_DESCRIPTION <- factor(geo_incidents$OFFENSE_DESCRIPTION)
qmplot(LONGITUDE, LATITUDE, data = geo_incidents, maptype = "toner-lite", geom = "density2d", color = I("red"))
qmplot(LONGITUDE, LATITUDE, data = geo_incidents, geom = "blank",
zoom = 15, maptype = "toner-background", darken = .7, legend = "topleft"
) +
stat_density_2d(aes(fill = ..level..), geom = "polygon", alpha = .3, color = NA) +
scale_fill_gradient2("Incidents\nFourwo Years", low = "white", mid = "yellow", high = "red", midpoint = 45)
#All the plots shown above only reveal us the distribution of crimes in the whole city.
#However, we have no idea with the internal factors which effect the distribution.
#At the very begining, we tried to figure out the correlation between the amount of incidents
#with space and time. But, we found this is helpless.
#We cannot study the trending in a specific area without defined a specific time. And, since
#the total amount of incidents in an area increasing with the time flows. So, we decide to see
#the relation between different types of crimes with the area in which the crimes happened.
#As well as the relation between the total amount of crimes happend in a specific weekday and
#areas
library(stringr)
incidents$dim <- str_sub(incidents$ymd, start = 6L, end = 10L)
#These 11 plots reveal the distribution of the 11 types of crimes in the city
qmplot(LONGITUDE, LATITUDE, data = geo_incidents, maptype = "toner-background", color = OFFENSE_DESCRIPTION) +
facet_wrap(~ OFFENSE_DESCRIPTION)
#Now, we hope to see the distribution
#of different types of crimes in a week as well as in a year. The heatmap is used.
crimesDay <- aggregate(total_incidents$incidents_Description,
by = list(total_incidents$incidents_Description, total_incidents$incidents_wdays), FUN = length)
names(crimesDay) <- c("crimeDescription", "weekday", "count")
class(crimesDay$weekday)
factor(crimesDay$weekday)
crimesDay$weekday <- factor(crimesDay$weekday)
crimesDay <- crimesDay[order(crimesDay$count, decreasing = TRUE), ]
ggplot(crimesDay, aes(crimeDescription, weekday)) + geom_tile(aes(fill = count),colour = "white", na.rm = TRUE) +
scale_fill_gradient(low = col1, high = col2) +
guides(fill=guide_legend(title="Total Incidents")) +
theme_bw() + theme_minimal() +
labs(title = "Heatmap of LR crime distribution per week",
x = "Crime description", y = "Day of Week") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.x = element_text(angle = 90, vjust = 0.5))
#The distribution of crimes in each month
monthly_crimes <- aggregate(total_incidents$incidents_Description,
by = list(total_incidents$incidents_Description, as.factor(total_incidents$incidents_month)), FUN = length)
names(monthly_crimes) <- c("crimeDescription", "month", "count")
monthly_crimes$month <- factor(monthly_crimes$month, levels = c("JAN", "FEB", "MAR", "APR",
"MAY", "JUN", "JUL", "AUG",
"SEP", "OCT", "NOV", "DEC"))
monthly_crimes <- monthly_crimes[order(monthly_crimes$count, decreasing = TRUE), ]
ggplot(monthly_crimes, aes(crimeDescription, month)) + geom_tile(aes(fill = count),colour = "white", na.rm = TRUE) +
scale_fill_gradient(low = col1, high = col2) +
guides(fill=guide_legend(title="Monthly Crimes")) +
theme_bw() + theme_minimal() +
labs(title = "Heatmap of LR crime distribution per month for the past four years",
x = "Crime description", y = "Month") +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
axis.text.x = element_text(angle = 90, vjust = 0.5))
#Now, we want to see the distribution of crimes in each moth, no matter which type of crimes
#Bar plot will be adopted
for (i in 1 : length(total_incidents$incidents_month)) {
if (grepl("Sep", total_incidents$incidents_month[i])) {
total_incidents$incidents_month[i] <- gsub("Sep", "SEP", total_incidents$incidents_month[i])
}
}
month_all <- aggregate(total_incidents$incidents_month, by = list(total_incidents$incidents_month), FUN = length)
names(month_all) <- c("Month", "Total amount")
month_all$Month <- factor(month_all$Month, levels = c("JAN", "FEB", "MAR", "APR",
"MAY", "JUN", "JUL", "AUG",
"SEP", "OCT", "NOV", "DEC"))
ggplot(month_all, aes(x = Month, y = `Total amount`), colo) +
geom_bar(stat = "identity", width = 0.8, fill = "red")
#Do this to four years separately
#total_incidents$year <- year(total_incidents$incidents_ymd)
#total_incidents$incidents_month <- factor(total_incidents$incidents_month, levels = c("JAN", "FEB", "MAR", "APR",
#                                                                      "MAY", "JUN", "JUL", "AUG",
#                                                                      "SEP", "OCT", "NOV", "DEC"))
#factor(total_incidents$year)
separated_by_year <- data.frame(cbind(total_incidents$incidents_month, total_incidents$incidents_Description,
total_incidents$year))
head(separated_by_year)
names(separated_by_year) <- c("Month", "Description", "Year")
separated_by_year <- aggregate(separated_by_year$Description, by = list(separated_by_year$Month, separated_by_year$Year), FUN = length)
names(separated_by_year) <- c("Month", "Year", "Amount")
ggplot(separated_by_year, aes(x = Month, y = Amount)) +
geom_bar(stat = "identity", width = 0.8, fill = "red") +
facet_wrap(~Year)
daily_temp <- read.table("/Users/mali/Documents/myGit/LRCrimeStudy/data/purged_daily_climate_Of_LR_2015-2018.csv",
head=TRUE, sep=",", fill=TRUE, stringsAsFactors=F)
daily_temp$X <- NULL
daily_temp$dailyAvg <- (daily_temp$dailyMax + daily_temp$dailyMin) / 2
colnames(daily_temp) <- c("date", "min", "max", "avg")
daily_temp
head(total_incidents)
daily_total_crimes <- data.frame(total_incidents$incidents_ymd, total_incidents$incidents_Number)
daily_total_crimes
daily_total_crimes <- aggregate(daily_total_crimes$total_incidents.incidents_Number, by = list(daily_total_crimes$total_incidents.incidents_ymd), FUN = length)
colnames(daily_total_crimes) <- c("date", "daily_total")
head(daily_total_crimes)
head(daily_temp)
class(daily_temp$date[1])
class(daily_total_crimes$date[1])
daily_total_crimes <- data.frame(total_incidents$incidents_ymd, total_incidents$incidents_Number, stringsAsFactors = FALSE)
daily_total_crimes <- aggregate(daily_total_crimes$total_incidents.incidents_Number, by = list(daily_total_crimes$total_incidents.incidents_ymd), FUN = length)
class(daily_total_crimes$date[1])
daily_total_crimes
colnames(daily_total_crimes) <- c("date", "daily_total")
class(daily_total_crimes$date[1])
class(daily_temp$date[1])
daily_temp$date[1] == daily_total_crimes$date[1]
daily_temp$date[1]
daily_total_crimes$date[1]
as.Date.character(daily_temp$date[1]) == as.Date.character(daily_total_crimes$date[1])
daily_total_crimes$date <- as.Date.character(daily_total_crimes$date)
daily_temp$date <- as.Date.character(daily_temp$date)
combination_information <- merge(daily_total_crimes, daily_temp, by = "date")
combination_information
combination_information
combination_information$year <- year(combination_information$date)
combination_information$year
combination_infor_2015 <- combination_information[combination_information$year == 2015, ]
combination_infor_2016 <- combination_information[combination_information$year == 2016, ]
combination_infor_2017 <- combination_information[combination_information$year == 2017, ]
combination_infor_2018 <- combination_information[combination_information$year == 2018, ]
combination_infor_2015
combination_information$month <- month(combination_information$date)
combination_infor_2015 <- combination_information[combination_information$year == 2015, ]
combination_infor_2016 <- combination_information[combination_information$year == 2016, ]
combination_infor_2017 <- combination_information[combination_information$year == 2017, ]
combination_infor_2018 <- combination_information[combination_information$year == 2018, ]
sp_2015<-ggplot(combination_infor_2015, aes(x = date, y = daily_total, color = dailyAvg)) +
geom_point()
sp_2015
combination_infor_2015
sp_2015<-ggplot(combination_infor_2015, aes(x = date, y = daily_total, color = avg)) +
geom_point()
sp_2015
sp_2015<-ggplot(combination_infor_2015, aes(x = date, y = daily_total, color = avg)) +
geom_point(aes(size = daily_total))
sp_2015
sp_2015<-ggplot(combination_infor_2015, aes(x = date, y = daily_total, color = avg)) +
geom_point(aes(size = daily_total)) +
facet_grid(~month)
sp_2015
sp_2015<-ggplot(combination_infor_2015, aes(x = date, y = daily_total, color = avg)) +
geom_point(aes(size = daily_total)) +
facet_wrap(~month)
sp_2015
sp_2015<-ggplot(combination_infor_2015, aes(x = date, y = daily_total, color = avg)) +
geom_point(aes(size = daily_total)) +
facet_grid(~month, scales = "free")
sp_2015
sp_2015<-ggplot(combination_infor_2015, aes(x = date, y = daily_total, color = avg)) +
geom_point(aes(size = daily_total)) +
facet_grid(~month, scales = "free", space = "free_x")
sp_2015
sp_2015<-ggplot(combination_infor_2015, aes(x = date, y = daily_total, color = avg)) +
geom_point(aes(size = daily_total)) +
facet_grid(date~month, scales = "free", space = "free_x")
sp_2015
